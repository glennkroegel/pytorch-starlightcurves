{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import astropy as ap\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "# from astropy.io import fits\n",
    "import pdb\n",
    "from scipy.ndimage.filters import maximum_filter1d\n",
    "import glob\n",
    "import fitsio as fits\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data_utils\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence, pad_sequence\n",
    "from torch.distributions.normal import Normal\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "sys.path.insert(1, '../latent_ode/')\n",
    "import latent_ode.lib as ode\n",
    "import latent_ode.lib.utils as utils\n",
    "from latent_ode.lib.latent_ode import LatentODE\n",
    "from latent_ode.lib.encoder_decoder import Encoder_z0_ODE_RNN, Decoder\n",
    "from latent_ode.lib.diffeq_solver import DiffeqSolver\n",
    "from latent_ode.lib.ode_func import ODEFunc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from latent_rnn import create_LatentODE_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obsrv_std = torch.Tensor([0.1]).to(device)\n",
    "z0_prior = Normal(torch.Tensor([0.0]).to(device), torch.Tensor([1.]).to(device))\n",
    "input_dim = 1\n",
    "model = create_LatentODE_model(input_dim, z0_prior, obsrv_std).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# state = torch.load('latent_ode_state.pth.tar')\n",
    "state = torch.load('latent_ode_state_ucr_extrap.pth.tar', map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(state['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = torch.load('ucr_train_extrap.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(z, t):\n",
    "    sol_y = model.diffeq_solver.sample_traj_from_prior(z, t, n_traj_samples = 1)\n",
    "    out = model.decoder(sol_y)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_us = []\n",
    "z_stds = []\n",
    "truths = []\n",
    "ts = []\n",
    "recs = []\n",
    "rec_mins = []\n",
    "rec_maxs = []\n",
    "rec_stds = []\n",
    "samples = []\n",
    "for batch in tqdm(loader):\n",
    "    observed = batch['observed_data'].to(device)\n",
    "    true = batch['data_to_predict'].to(device)\n",
    "    truths.extend([x for x in true])\n",
    "    mask = batch['observed_mask'].to(device)\n",
    "    mask_pred = batch['mask_predicted_data']#.to(device)\n",
    "#     mask_pred = torch.ones(mask.shape)\n",
    "    x = torch.cat((observed, mask), -1)\n",
    "#     if not mask_pred:\n",
    "#         mask_pred = torch.ones(true.shape)\n",
    "    mask_pred = mask_pred.to(device)\n",
    "    x2 = torch.cat((true, mask_pred), -1)\n",
    "    t1 = batch['observed_tp'].to(device)\n",
    "    t2 = batch['tp_to_predict'].to(device)\n",
    "    t = torch.cat([t1,t2])\n",
    "#     truth_time_steps = t[mask.nonzero()]\n",
    "#     ts.append(t.detach().cpu())\n",
    "    z_u, z_std = model.encoder_z0.forward(x, t1)\n",
    "    rec = model.get_reconstruction(\n",
    "        time_steps_to_predict=t, truth=observed, truth_time_steps=t1, mask=mask, n_traj_samples=50)[0].detach().cpu().squeeze()\n",
    "    rec_u = rec.mean(dim=0)\n",
    "    rec_max = rec.max(dim=0)\n",
    "    rec_min = rec.min(dim=0)\n",
    "    rec_std = rec.std(dim=0)\n",
    "    recs.extend([x for x in rec_u])\n",
    "    rec_stds.extend([x for x in rec_std])\n",
    "#     z_u = z_u.squeeze()\n",
    "    s = sample(z_u, t)[0]\n",
    "    samples.extend([x for x in s])\n",
    "    z_u = z_u.detach().cpu()\n",
    "    z_std = z_std.detach().cpu()\n",
    "    z_us.append(z_u)\n",
    "    z_stds.append(z_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(rec_stds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = samples[ix].detach().cpu().numpy().reshape(1,-1)\n",
    "y = recs[ix].numpy().reshape(1,-1)\n",
    "x = t.detach().cpu().numpy().reshape(1,-1)\n",
    "y_true = truths[ix].detach().cpu().numpy().reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_predict = np.concatenate([x, y], axis=0).T\n",
    "d_true = np.concatenate([x[:,25:], y_true], axis=0).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predict = pd.DataFrame(d_predict, columns = ['t', 'value'])\n",
    "df_predict['type'] = 'prediction'\n",
    "df_truth = pd.DataFrame(d_true, columns = ['t', 'value'])\n",
    "df_truth['type'] = 'truth'\n",
    "df = pd.concat([df_predict, df_truth], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x='t', y='value', data=df, hue='type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Multiple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = torch.load('ucr_train_extrap.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = batch['observed_data'][ix].unsqueeze(0).to(device)\n",
    "y2 = batch['data_to_predict'][ix].unsqueeze(0).to(device)\n",
    "mask = batch['observed_mask'][ix].unsqueeze(0).to(device)\n",
    "t1 = batch['observed_tp'].to(device)\n",
    "t2 = batch['tp_to_predict'].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec = model.get_reconstruction(\n",
    "    time_steps_to_predict=t2, \n",
    "    truth=y1, \n",
    "    truth_time_steps=t1, \n",
    "    mask=mask, \n",
    "    n_traj_samples=10000)[0].detach().cpu().squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec.max(0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = rec.mean(dim=0).detach().cpu().numpy()\n",
    "maxs = rec.max(dim=0)[0].detach().cpu().numpy()\n",
    "mins = rec.min(dim=0)[0].detach().cpu().numpy()\n",
    "recs = rec.detach().cpu().numpy()\n",
    "y1 = y1.squeeze().detach().cpu().numpy()\n",
    "y2 = y2.squeeze().detach().cpu().numpy()\n",
    "t1 = t1.detach().cpu().numpy()\n",
    "t2 = t2.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-darkgrid')\n",
    "font = {'family': 'serif',\n",
    "        'color':  'grey',\n",
    "        'weight': 'light',\n",
    "        'size': 12,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/12957582/plot-yerr-xerr-as-shaded-region-rather-than-error-bars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "ax = plt.subplot(111)\n",
    "# for i, r in enumerate(recs):\n",
    "#     if i == 0:\n",
    "#         ax.plot(t2, r, marker='', color='grey', linewidth=1, alpha=0.4, label='Sampled Trajectories')\n",
    "#     ax.plot(t2, r, marker='', color='grey', linewidth=1, alpha=0.4)\n",
    "ax.plot(t2, u, marker='', color='orange', linewidth=2, alpha=1, label='Model Trajectory (Mean)')\n",
    "ax.plot(t2, maxs, marker='', color='grey', linewidth=2, alpha=0.1)\n",
    "ax.plot(t2, mins, marker='', color='grey', linewidth=2, alpha=0.1)\n",
    "ax.plot(t1, y1, marker='+', color='black', linestyle='None', alpha=0.4, markersize=7, label='Conditioned Observations')\n",
    "ax.plot(t2, y2, marker='+', color='red', linestyle='None', alpha=0.4, markersize=7, label='Out of Sample Observations')\n",
    "plt.xlabel(\"Time\", fontdict=font)\n",
    "plt.ylabel(\"Magnitude\", fontdict=font)\n",
    "plt.fill_between(t2, mins, maxs, alpha=0.05, label='Model Error bound')\n",
    "ax.legend(loc='center left', bbox_to_anchor=(1.0, 0.5),\n",
    "          ncol=1, fancybox=True, shadow=True)\n",
    "ax.tick_params(\n",
    "    axis='both',          # changes apply to the x-axis\n",
    "    which='both',      # both major and minor ticks are affected\n",
    "    bottom=False,      # ticks along the bottom edge are off\n",
    "    top=False,         # ticks along the top edge are off\n",
    "    labelbottom=False,\n",
    "    labelleft=False,\n",
    "    right=False, \n",
    "    left=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
