{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import astropy as ap\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "# from astropy.io import fits\n",
    "import pdb\n",
    "from scipy.ndimage.filters import maximum_filter1d\n",
    "import glob\n",
    "import fitsio as fits\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data_utils\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence, pad_sequence\n",
    "from torch.distributions.normal import Normal\n",
    "from tqdm import tqdm\n",
    "from loading import TessDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "sys.path.insert(1, '../latent_ode/')\n",
    "import latent_ode.lib as ode\n",
    "import latent_ode.lib.utils as utils\n",
    "from latent_ode.lib.latent_ode import LatentODE\n",
    "from latent_ode.lib.ode_rnn import ODE_RNN\n",
    "from latent_ode.lib.encoder_decoder import Encoder_z0_ODE_RNN, Decoder\n",
    "from latent_ode.lib.diffeq_solver import DiffeqSolver\n",
    "from latent_ode.lib.ode_func import ODEFunc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################\n",
    "# Options\n",
    "input_dim = 1\n",
    "classif_per_tp = False\n",
    "n_labels = 1\n",
    "niters = 1\n",
    "status_properties = ['loss']\n",
    "latent_dim = 40\n",
    "\n",
    "##################################################################\n",
    "# Model\n",
    "obsrv_std = torch.Tensor([0.1]).to(device)\n",
    "z0_prior = Normal(torch.Tensor([0.0]).to(device), torch.Tensor([1.]).to(device))\n",
    "gru_units = 40\n",
    "n_ode_gru_dims = latent_dim\n",
    "\t\t\t\t\n",
    "ode_func_net = utils.create_net(n_ode_gru_dims, n_ode_gru_dims, \n",
    "    n_layers = 2, n_units = 100, nonlinear = nn.Tanh)\n",
    "\n",
    "rec_ode_func = ODEFunc(\n",
    "    input_dim = input_dim, \n",
    "    latent_dim = n_ode_gru_dims,\n",
    "    ode_func_net = ode_func_net,\n",
    "    device = device).to(device)\n",
    "\n",
    "z0_diffeq_solver = DiffeqSolver(input_dim, rec_ode_func, \"dopri5\", latent_dim, \n",
    "    odeint_rtol = 1e-3, odeint_atol = 1e-4, device = device)\n",
    "\n",
    "model = ODE_RNN(input_dim=input_dim, latent_dim=latent_dim, \n",
    "            n_gru_units = 100, n_units = 100, device = device, \n",
    "\t\t\tz0_diffeq_solver = z0_diffeq_solver,\n",
    "\t\t\tconcat_mask = True, obsrv_std = obsrv_std,\n",
    "\t\t\tuse_binary_classif = False,\n",
    "\t\t\tclassif_per_tp = False,\n",
    "\t\t\tn_labels = 1,\n",
    "\t\t\ttrain_classif_w_reconstr = False\n",
    "\t\t\t).to(device)\n",
    "\n",
    "disable_bias = True\n",
    "if disable_bias:\n",
    "    for module in model.modules():\n",
    "        if hasattr(module, 'bias'):\n",
    "            module.bias = None\n",
    "\n",
    "##################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = 'ode_rnn_state_tess.pth.tar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = torch.load(model_file, map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(state['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = torch.load('gaia_train.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_us = []\n",
    "z_stds = []\n",
    "truths = []\n",
    "ts = []\n",
    "recs = []\n",
    "rec_stds = []\n",
    "samples = []\n",
    "for batch in tqdm(loader):\n",
    "    observed = batch['observed_data'].to(device)\n",
    "    true = batch['data_to_predict'].to(device)\n",
    "    truths.extend([x for x in true])\n",
    "    mask = batch['observed_mask'].to(device)\n",
    "    mask_pred = batch['mask_predicted_data']#.to(device)\n",
    "#     mask_pred = torch.ones(mask.shape)\n",
    "    x = torch.cat((observed, mask), -1)\n",
    "#     if not mask_pred:\n",
    "#         mask_pred = torch.ones(true.shape)\n",
    "    mask_pred = mask_pred.to(device)\n",
    "    x2 = torch.cat((true, mask_pred), -1)\n",
    "    t = batch['observed_tp'].to(device)\n",
    "#     truth_time_steps = t[mask.nonzero()]\n",
    "#     ts.append(t.detach().cpu())\n",
    "    z_u, z_std = model.ode_gru.forward(x, t)\n",
    "    rec = model.get_reconstruction(\n",
    "        time_steps_to_predict=t, data=observed, truth_time_steps=t, mask=mask, n_traj_samples=20)[0].detach().cpu().squeeze()\n",
    "#     rec_u = rec.mean(dim=0)\n",
    "#     rec_std = rec.std(dim=0)\n",
    "    recs.extend([x for x in rec])\n",
    "#     rec_stds.extend([x for x in rec_std])\n",
    "#     z_u = z_u.squeeze()\n",
    "    z_u = z_u.detach().cpu()\n",
    "    z_std = z_std.detach().cpu()\n",
    "    z_us.append(z_u)\n",
    "    z_stds.append(z_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = samples[ix].detach().cpu().numpy().reshape(1,-1)\n",
    "y = recs[ix].numpy().reshape(1,-1)\n",
    "x = t.detach().cpu().numpy().reshape(1,-1)\n",
    "y_true = truths[ix].detach().cpu().numpy().reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_predict = np.concatenate([x, y], axis=0).T\n",
    "d_true = np.concatenate([x, y_true], axis=0).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predict = pd.DataFrame(d_predict, columns = ['t', 'value'])\n",
    "df_predict['type'] = 'prediction'\n",
    "df_truth = pd.DataFrame(d_true, columns = ['t', 'value'])\n",
    "df_truth['type'] = 'truth'\n",
    "df = pd.concat([df_predict, df_truth], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x='t', y='value', data=df, hue='type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Multiple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = torch.load('tess_cv.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix = 29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observed = batch['observed_data'][ix].unsqueeze(0).to(device)\n",
    "true = batch['data_to_predict'][ix].unsqueeze(0).to(device)\n",
    "mask = batch['observed_mask'][ix].unsqueeze(0).to(device)\n",
    "t = batch['observed_tp'].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = t.min().item()\n",
    "# b = t.max().item()\n",
    "# step = (b-a)/1000\n",
    "# t=torch.arange(a,b,step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec = model.get_reconstruction(\n",
    "    time_steps_to_predict=t, \n",
    "    data=observed, \n",
    "    truth_time_steps=t, \n",
    "    mask=mask, \n",
    "    n_traj_samples=20)[0].detach().cpu().squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec = rec.detach().cpu().numpy()\n",
    "truth = true.detach().squeeze().cpu().numpy()\n",
    "obs = observed.squeeze().detach().cpu().numpy()\n",
    "t_obs = t[obs != 0]\n",
    "obs = obs[obs != 0]\n",
    "t = t.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-darkgrid')\n",
    "font = {'family': 'serif',\n",
    "        'color':  'grey',\n",
    "        'weight': 'light',\n",
    "        'size': 12,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "ax = plt.subplot(111)\n",
    "ax.plot(t, rec, marker='', color='orange', linewidth=2, alpha=1, label='Model prediction')\n",
    "ax.plot(t_obs, obs, marker='+', color='black', linestyle='None', alpha=0.7, markersize=7, label='Observations')\n",
    "plt.xlabel(\"Time (MJD)\", fontdict=font)\n",
    "plt.ylabel(\"Normalized Flux\", fontdict=font)\n",
    "ax.legend(loc='center left', bbox_to_anchor=(1.0, 0.9),\n",
    "          ncol=1, fancybox=True, shadow=True)\n",
    "# ax.tick_params(\n",
    "#     axis='both',          # changes apply to the x-axis\n",
    "#     which='both',      # both major and minor ticks are affected\n",
    "#     bottom=False,      # ticks along the bottom edge are off\n",
    "#     top=False,         # ticks along the top edge are off\n",
    "#     labelbottom=False,\n",
    "#     labelleft=False,\n",
    "#     right=False, \n",
    "#     left=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
