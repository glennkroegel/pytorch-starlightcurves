{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import astropy as ap\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "# from astropy.io import fits\n",
    "import pdb\n",
    "from scipy.ndimage.filters import maximum_filter1d\n",
    "import glob\n",
    "import fitsio as fits\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data_utils\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence, pad_sequence\n",
    "from torch.distributions.normal import Normal\n",
    "from tqdm import tqdm\n",
    "from utils import collate_interp_sparse_sectors\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "sys.path.insert(1, '../latent_ode/')\n",
    "import latent_ode.lib as ode\n",
    "import latent_ode.lib.utils as utils\n",
    "from latent_ode.lib.latent_ode import LatentODE\n",
    "from latent_ode.lib.ode_rnn import ODE_RNN\n",
    "from latent_ode.lib.encoder_decoder import Encoder_z0_ODE_RNN, Decoder\n",
    "from latent_ode.lib.diffeq_solver import DiffeqSolver\n",
    "from latent_ode.lib.ode_func import ODEFunc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ode_rnn_tess_sectors import create_ODERNN_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_ODERNN_model()\n",
    "# model = create_LatentODE_model(input_dim, z0_prior, obsrv_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = 'ode_rnn_state_tess_sectors.pth.tar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = torch.load(model_file, map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(state['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(z, t):\n",
    "    sol_y = model.diffeq_solver.sample_traj_from_prior(z, t, n_traj_samples = 100)\n",
    "    res = model.decoder(sol_y)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indir = 'tess/all_data/z_normalized/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sectors = os.listdir(indir); sectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = {}\n",
    "for i in sectors:\n",
    "    sector = str(i)\n",
    "    c = os.path.join(indir, sector, '*.npy')\n",
    "    files = glob.glob(c)\n",
    "    for f in files:\n",
    "        d = np.load(f)\n",
    "        t1 = d[0].min()\n",
    "        t2 = d[0].max()\n",
    "        l = len(d[0])\n",
    "        basename = os.path.basename(f)\n",
    "        summary = {'path': f, 't1': t1, 't2': t2, 'l': l, 'sector': sector}\n",
    "        res[basename] = summary\n",
    "\n",
    "df = pd.DataFrame(res).T\n",
    "groups=df.groupby(['sector','l'])['path'].apply(lambda x: list(x)).tolist()\n",
    "print(groups)\n",
    "print(\"Total groups: {0}\", len(groups))\n",
    "bs = batch_size\n",
    "batches = []\n",
    "for group in groups:\n",
    "    mini_batches=[group[i:(i+bs)] for i in range(0, len(group), bs)]\n",
    "    for b in mini_batches:\n",
    "        batches.append(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['l'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proc_batch(batch):\n",
    "    data = [np.load(f).astype(np.float32) for f in batch]\n",
    "    data = torch.FloatTensor(data)\n",
    "    inp = collate_interp_sparse_sectors(data)\n",
    "    observed = inp['observed_data'].to(device)\n",
    "    true = inp['data_to_predict'].to(device)\n",
    "    mask = inp['observed_mask'].to(device)\n",
    "    t = inp['observed_tp'].to(device)\n",
    "    x = torch.cat((observed, mask), -1)\n",
    "    try:\n",
    "        z_u, z_std = model.encoder_z0.forward(x, t)\n",
    "    except:\n",
    "        z_u, z_std = model.ode_gru.forward(x, t)\n",
    "    return z_u, t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batches = []\n",
    "# for i in tqdm(range(0, len(files)+1, batch_size)):\n",
    "#     batch = files[i:i+batch_size]\n",
    "#     batches.append(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# proc_batch(batches[-1])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_vecs = []\n",
    "for i, batch in tqdm(enumerate(batches)):\n",
    "    batch_vecs, t = proc_batch(batch)\n",
    "    batch_vecs = batch_vecs.squeeze().detach().cpu().numpy()\n",
    "    all_vecs.append(batch_vecs)\n",
    "    if i == 3:\n",
    "        break\n",
    "# all_vecs = np.concatenate([x for x in all_vecs])\n",
    "# all_vecs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.basename(batch[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_vecs = [x for a in all_vecs for x in a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [x for a in batches[:4] for x in a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(len(files) == len(all_vecs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outp = {}\n",
    "for i, f in enumerate(files):\n",
    "    series = np.load(f)[1]\n",
    "    outp[i] = {'filename': f, 'basename': os.path.basename(f).replace('.npy',''), 'vec': all_vecs[i], 'series': series}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_pickle(outp, 'results.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_vec(z, dim=50):\n",
    "    t = np.arange(0,len(z))\n",
    "    q = np.stack([t,z])\n",
    "    data = torch.FloatTensor(q.astype(np.float32))\n",
    "    data = data.unsqueeze(0)\n",
    "    inp = collate_interp_sparse_sectors(data)\n",
    "    observed = inp['observed_data'].to(device)\n",
    "    true = inp['data_to_predict'].to(device)\n",
    "    mask = inp['observed_mask'].to(device)\n",
    "    t = inp['observed_tp'].to(device)\n",
    "    x = torch.cat((observed, mask), -1)\n",
    "    try:\n",
    "        z_u, z_std = model.encoder_z0.forward(x, t)\n",
    "    except:\n",
    "        z_u, z_std = model.ode_gru.forward(x, t)\n",
    "    z_u = z_u.view(1, dim).detach().cpu().numpy()\n",
    "    return z_u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = np.random.randn(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v=calc_vec(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
